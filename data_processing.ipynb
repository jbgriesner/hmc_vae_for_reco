{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import fileinput\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.sparse\n",
    "import pandas as pd\n",
    "\n",
    "from src.utils import concatenate_files, train_tune_test_split, filter_rows, split_train_test_proportion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# All the constants of this notebook are defined in this cell\n",
    "\n",
    "foursquare_raw_DIR = './data/raw/foursquare'\n",
    "gowalla_raw_DIR = './data/raw/gowalla'\n",
    "ml100_raw_DIR = './data/raw/ml-100k'\n",
    "ml25_raw_DIR = './data/raw/ml-25m'\n",
    "\n",
    "foursquare_clean_DIR = './data/clean/foursquare'\n",
    "gowalla_clean_DIR = './data/clean/gowalla'\n",
    "ml100_clean_DIR = './data/clean/ml-100k'\n",
    "ml25_clean_DIR = './data/clean/ml-25m'\n",
    "\n",
    "foursquare_checkins_file = f\"{foursquare_raw_DIR}/checkins\"\n",
    "foursquare_pois_file = f\"{foursquare_raw_DIR}/pois\"\n",
    "gowalla_checkins_file = f\"{gowalla_raw_DIR}/checkins\"\n",
    "gowalla_pois_file = f\"{gowalla_raw_DIR}/pois\"\n",
    "ml100_ratings_file = f\"{ml100_raw_DIR}/ratings.csv\"\n",
    "ml25_ratings_file = f\"{ml25_raw_DIR}/ratings\"\n",
    "\n",
    "foursquare_clicks = 1000000\n",
    "gowalla_clicks = 1000000\n",
    "ml_25_clicks = 20000000\n",
    "\n",
    "# for auto-reloading external modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenating input files\n",
    "- because of file size limitation of github the datasets are splitted in small pieces.\n",
    "- they must be first concatenating into one file\n",
    "- so just do this once to get one file for each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenate_files(foursquare_checkins_file, f\"{foursquare_raw_DIR}/*checkins_0*\")\n",
    "concatenate_files(foursquare_pois_file, f\"{foursquare_raw_DIR}/*pois_0*\")\n",
    "\n",
    "concatenate_files(gowalla_checkins_file, f\"{gowalla_raw_DIR}/*checkins_0*\")\n",
    "concatenate_files(gowalla_pois_file, f\"{gowalla_raw_DIR}/*pois_0*\")\n",
    "\n",
    "concatenate_files(ml25_ratings_file, f\"{ml25_raw_DIR}/*ratings_0*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "foursquare_checkins = pd.read_csv(foursquare_checkins_file, error_bad_lines=False, nrows=foursquare_clicks, sep='\\t', usecols=[0,1], names=['user', 'item'])\n",
    "gowalla_checkins = pd.read_csv(gowalla_checkins_file, error_bad_lines=False, nrows=gowalla_clicks, usecols=[0,1], names=['user', 'item'])\n",
    "# ml25_ratings = pd.read_csv(ml25_ratings_file, error_bad_lines=False, header=0, nrows=ml_25_clicks, usecols=[0, 1, 2], names=['user', 'item', 'rating'])\n",
    "# ml100_ratings = pd.read_csv(ml100_ratings_file, error_bad_lines=False, header=0, usecols=[0, 1, 2], names=['user', 'item', 'rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml100_ratings = ml100_ratings[ml100_ratings['rating'] > 3.5]\n",
    "ml25_ratings = ml25_ratings[ml25_ratings['rating'] > 3.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df(df_name):\n",
    "    dfs = {\n",
    "        'foursquare': [foursquare_checkins, foursquare_clean_DIR],\n",
    "        'gowalla': [gowalla_checkins, gowalla_clean_DIR],\n",
    "        'ml25': [ml25_ratings, ml25_clean_DIR],\n",
    "        'ml100': [ml100_ratings, ml100_clean_DIR ]\n",
    "    }\n",
    "    return dfs.get(df_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In foursquare, after filtering, there are 286433 watching events from 28932 users and 35804 items (sparsity: 0.028%)\n",
      "0 users sampled\n",
      "1000 users sampled\n",
      "0 users sampled\n",
      "1000 users sampled\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 1/2 [00:05<00:05,  5.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In gowalla, after filtering, there are 548990 watching events from 5815 users and 40504 items (sparsity: 0.233%)\n",
      "0 users sampled\n",
      "0 users sampled\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:07<00:00,  3.70s/it]\n"
     ]
    }
   ],
   "source": [
    "# for df_name in tqdm(['foursquare', 'gowalla', 'ml25', 'ml100']):\n",
    "for df_name in tqdm(['foursquare', 'gowalla']):\n",
    "    df_info = get_df(df_name)\n",
    "    df, clean_dir = df_info[0], df_info[1] \n",
    "    \n",
    "    raw_data, user_activity, item_popularity = filter_rows(df)\n",
    "    sparsity = 1. * raw_data.shape[0] / (user_activity.shape[0] * item_popularity.shape[0])\n",
    "\n",
    "    print(f\"In {df_name}, after filtering, there are %d watching events from %d users and %d items (sparsity: %.3f%%)\" % \n",
    "      (raw_data.shape[0], user_activity.shape[0], item_popularity.shape[0], sparsity * 100))\n",
    "    \n",
    "    unique_uid = user_activity.index\n",
    "\n",
    "    np.random.seed(98765)\n",
    "    idx_perm = np.random.permutation(unique_uid.size)\n",
    "    unique_uid = unique_uid[idx_perm]\n",
    "    \n",
    "    # create train/validation/test users\n",
    "    n_users = unique_uid.size\n",
    "    \n",
    "    if df_name == 'foursquare':\n",
    "        n_heldout_users = 2000\n",
    "    if df_name == 'gowalla':\n",
    "        n_heldout_users = 500\n",
    "    if df_name == 'ml100':\n",
    "        n_heldout_users = 100\n",
    "\n",
    "    tr_users = unique_uid[:(n_users - n_heldout_users * 2)]\n",
    "    vd_users = unique_uid[(n_users - n_heldout_users * 2): (n_users - n_heldout_users)]\n",
    "    te_users = unique_uid[(n_users - n_heldout_users):]\n",
    "    \n",
    "    assert tr_users.shape[0] > 0\n",
    "    assert vd_users.shape[0] > 0\n",
    "    assert te_users.shape[0] > 0\n",
    "    \n",
    "    train_plays = raw_data.loc[raw_data['user'].isin(tr_users)]\n",
    "    unique_sid = pd.unique(train_plays['item'])\n",
    "    \n",
    "    show2id = dict((sid, i) for (i, sid) in enumerate(unique_sid))\n",
    "    profile2id = dict((pid, i) for (i, pid) in enumerate(unique_uid))\n",
    "    \n",
    "    def numerize(tp):\n",
    "        uid = list(map(lambda x: profile2id[x], tp['user']))\n",
    "        sid = list(map(lambda x: show2id[x], tp['item']))\n",
    "        return pd.DataFrame(data={'uid': uid, 'sid': sid}, columns=['uid', 'sid'])\n",
    "    \n",
    "    with open(os.path.join(clean_dir, 'unique_sid.txt'), 'w') as f:\n",
    "        for sid in unique_sid:\n",
    "            f.write('%s\\n' % sid)\n",
    "            \n",
    "    vad_plays = raw_data.loc[raw_data['user'].isin(vd_users)]\n",
    "    vad_plays = vad_plays.loc[vad_plays['item'].isin(unique_sid)]\n",
    "    \n",
    "    vad_plays_tr, vad_plays_te = split_train_test_proportion(vad_plays)\n",
    "    \n",
    "    test_plays = raw_data.loc[raw_data['user'].isin(te_users)]\n",
    "    test_plays = test_plays.loc[test_plays['item'].isin(unique_sid)]\n",
    "\n",
    "    test_plays_tr, test_plays_te = split_train_test_proportion(test_plays)\n",
    "    \n",
    "    train_data = numerize(train_plays)\n",
    "    train_data.to_csv(os.path.join(clean_dir, 'train.csv'), index=False)\n",
    "\n",
    "    vad_data_tr = numerize(vad_plays_tr)\n",
    "    vad_data_tr.to_csv(os.path.join(clean_dir, 'validation_tr.csv'), index=False)\n",
    "\n",
    "    vad_data_te = numerize(vad_plays_te)\n",
    "    vad_data_te.to_csv(os.path.join(clean_dir, 'validation_te.csv'), index=False)\n",
    "    \n",
    "    test_data_tr = numerize(test_plays_tr)\n",
    "    test_data_tr.to_csv(os.path.join(clean_dir, 'test_tr.csv'), index=False)\n",
    "    \n",
    "    test_data_te = numerize(test_plays_te)\n",
    "    test_data_te.to_csv(os.path.join(clean_dir, 'test_te.csv'), index=False)\n",
    "    \n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
